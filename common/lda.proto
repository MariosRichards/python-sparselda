package lda;

// Copyright(c) 2013 python-sparselda project.
// Author: Lifeng Wang (ofandywang@gmail.com)
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
//
// Using Google Protocal Buffers (protobuf) to serialize corpus and the lda model.
//
// See https://developers.google.com/protocol-buffers/docs/pythontutorial for
// more details.

message WordPB {
    optional int32 id = 1;  // index of current word
    optional int32 topic = 2;  // topic assignment to current word
}

message DocumentPB {
    repeated WordPB words = 1;
}

message NonZeroPB {
    optional int32 topic = 1;
    optional int64 count = 2;
}

// the sparse topic histogram
message SparseTopicHistogramPB {
    repeated NonZeroPB non_zeros = 1;
}

// N(w|z)
message WordTopicHistogramPB {
    optional int32 word = 1;
    optional SparseTopicHistogramPB sparse_topic_hist = 2;
}

// N(z), the dense topic histogram.
message GlobalTopicHistogramPB {
    repeated int64 topic_counts = 1;
}

// Dirichlet prior
message HyperParamsPB {
    optional double topic_prior = 1;
    optional double word_prior = 2;
}

